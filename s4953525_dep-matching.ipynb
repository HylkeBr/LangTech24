{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Question Analysis\n",
    "\n",
    "The goal of this assignment is to write a more flexible version of the interactive QA system using syntactic analysis (SpaCy). As in the previous assignment, the system should be able to take a question in natural language (Dutch) as input, analyse the question, and generate a SPARQL query for it.\n",
    "\n",
    "## Assignment  // Additional requirements\n",
    "\n",
    "* Make sure that your system can analyse **at least two more question types**. E.g. questions that start with *Hoe lang/Hoe groot/Hoe oud*, *Hoe heet/Hoe noem*, *Hoeveel*, and questions where the property is expressed by a verb (*Wat eet, Waar leeft,*), Yes/No questions, *welke* questions, etc. \n",
    "* Apart from the techniques introduced in week 3 (matching tokens on the basis of their lemma or part-of-speech), also include at least one pattern where you use the **dependency relations** to find the relevant property or entity in the question. \n",
    "* Include 10 examples of questions that your system can handle, and that illustrate the fact that you cover additional question types\n",
    "\n",
    "## Examples\n",
    "\n",
    "Here is a non-representative list of questios and question types to consider. See the list with all questions for more examples\n",
    "\n",
    "* Hoe groot is een olifant?\n",
    "* Hoe heet de studie van insecten?\n",
    "* Hoe lang is een giraffe?\n",
    "* Hoe noem je de studie van mieren?\n",
    "* Hoeveel weegt een giraffe?\n",
    "* Waar komen koala's vandaan?\n",
    "* Waar leeft een orca?\n",
    "* Wanneer zijn vliegen ontstaan?\n",
    "* Welke kleur heeft een ijsbeer?\n",
    "* Zijn impala's een bedreigde diersoort?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import requests\n",
    "import time\n",
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"nl_core_news_lg\") # this loads the (large) model for analysing Dutch text\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Analysis with Spacy\n",
    "\n",
    "All the functionality of Spacy, as in the last assignment, is still available for doing question analysis. \n",
    "\n",
    "In addition, also use the dependency relations assigned by spacy. Note that a dependency relation is a directed, labeled, arc between two tokens in the input. In the example below, the system detects that *ijsbeer* is the subject of *heeft* (with label nsubj), and that *kleur* is a direct object (*obj*) dependent of *heeft*. Note also that *heeft* has lemma *hebben*. \n",
    "\n",
    "You can also use displacy to visualize the parse output. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hoe ADV advmod groot\n",
      "groot ADJ ROOT groot\n",
      "zijn AUX cop groot\n",
      "een DET det olifant\n",
      "olifant NOUN nsubj groot\n",
      "? PUNCT punct groot\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"nl\" id=\"cbed2a9fe6c645d2b68f6873a4dda102-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Hoe</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">groot</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">een</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">olifant?</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cbed2a9fe6c645d2b68f6873a4dda102-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cbed2a9fe6c645d2b68f6873a4dda102-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cbed2a9fe6c645d2b68f6873a4dda102-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cbed2a9fe6c645d2b68f6873a4dda102-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cbed2a9fe6c645d2b68f6873a4dda102-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cbed2a9fe6c645d2b68f6873a4dda102-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cbed2a9fe6c645d2b68f6873a4dda102-0-3\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cbed2a9fe6c645d2b68f6873a4dda102-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "question = 'Hoe groot is een olifant?'\n",
    "\n",
    "parse = nlp(question) # parse the input \n",
    "\n",
    "for word in parse : # iterate over the token objects \n",
    "    print(word.lemma_, word.pos_, word.dep_, word.head.lemma_)\n",
    "\n",
    "displacy.render(parse, jupyter=True, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating the parse tree\n",
    "\n",
    "The [Spacy web site](https://spacy.io/usage/linguistic-features#dependency-parse) explains a few handy functions that you can use to navigate in a dependency tree, using it for information extraction. (Question analysis for question answering is very similar to information extraction). \n",
    "\n",
    "### Phrases\n",
    "\n",
    "You can match with the full phrase that is the subject of the sentence, or any other dependency relation, using the **subtree** function \n",
    "\n",
    "### Chunks\n",
    "\n",
    "A nice feature is the fact that it can return chunks, combinations of a noun and adjectives (and a determiner, which you probably want to remove before searching on wikidata). See example below. \n",
    "\n",
    "Note that subtree often identifies the same string in the input as chunks. Differences occur for instance when a noun phrase contains another noun phrase. Chunks do not handle recursion, and thus would recognize two phrases, whereas  subtree would identify a single phrase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj Welke kleur\n",
      "nsubj een ijsbeer\n",
      "1\n",
      "welk kleur kleur obj heeft\n",
      "een ijsbeer ijsbeer nsubj heeft\n",
      "2\n",
      "nsubj Hoeveel slagen per minuut\n",
      "obj het hart van een giraffe\n",
      "3\n",
      "nsubj slag\n",
      "nmod minuut\n",
      "obj het hart\n",
      "nmod een giraffe\n"
     ]
    }
   ],
   "source": [
    "def phrase(word) :\n",
    "    children = []\n",
    "    for child in word.subtree :\n",
    "        children.append(child.text)\n",
    "    return \" \".join(children)\n",
    "\n",
    "question = nlp('Welke kleur heeft een ijsbeer?')\n",
    "\n",
    "for word in question:\n",
    "    if word.dep_ == 'nsubj' or word.dep_ == 'obj' :\n",
    "        phrase_text = phrase(word)\n",
    "        print(word.dep_, phrase_text)\n",
    "\n",
    "print(1)\n",
    "\n",
    "for chunk in question.noun_chunks:\n",
    "    print(chunk.lemma_, chunk.root.text, chunk.root.dep_,\n",
    "            chunk.root.head.text)\n",
    "\n",
    "print(2)\n",
    "complicated_question = nlp('Hoeveel slagen per minuut maakt het hart van een giraffe?')\n",
    "\n",
    "for word in complicated_question:\n",
    "    if word.dep_ == 'nsubj' or word.dep_ == 'obj' :\n",
    "        phrase_text = phrase(word)\n",
    "        print(word.dep_, phrase_text)\n",
    "\n",
    "print(3)\n",
    "for chunk in complicated_question.noun_chunks:\n",
    "    print(chunk.root.dep_, chunk.lemma_)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM PREVIOUS ASSIGNMENT #\n",
    "\n",
    "def getAnswer(query): \n",
    "    url = 'https://query.wikidata.org/sparql'\n",
    "    resultsx = requests.get(url, params={'query': query, 'format': 'json'})\n",
    "    \n",
    "    # To prevent a 429 request code (too many requests), wait 5 seconds when this occurs and try again.\n",
    "    if resultsx.status_code == 429:\n",
    "        time.sleep(5)\n",
    "        resultsx = requests.get(url, params={'query': query, 'format': 'json'})\n",
    "\n",
    "    results = resultsx.json()\n",
    "\n",
    "    # Check for yes/no answer\n",
    "    if 'boolean' in results.keys():\n",
    "        return results['boolean'] \n",
    "    else:\n",
    "        answers = []\n",
    "        varNames = results['head']['vars']\n",
    "        answerItems = results['results']['bindings']\n",
    "        \n",
    "        # Loop through multiple answers (if given)\n",
    "        for item in answerItems: \n",
    "            for varName in varNames:\n",
    "                answers.append(item[varName]['value'])\n",
    "    \n",
    "        return answers\n",
    "\n",
    "# Function to find the IDs of a search query\n",
    "def getIDs(query, p=False):\n",
    "    # Create parameters\n",
    "    url = 'https://www.wikidata.org/w/api.php'\n",
    "    params = {'action':'wbsearchentities',               \n",
    "              'language':'nl',\n",
    "              'uselang':'nl',\n",
    "              'format':'json',\n",
    "              'search': query}\n",
    "    if p: # If looking for property id\n",
    "        params['type'] = 'property'\n",
    "    json = requests.get(url,params).json()\n",
    "    # Get IDs from different answers\n",
    "    IDs = []\n",
    "    for search in json['search']:\n",
    "        IDs.append(search['id'])\n",
    "\n",
    "    return IDs\n",
    "\n",
    "# To filter on animals\n",
    "def animalID(ID):\n",
    "    query1 = 'SELECT ?ansLabel WHERE { wd:' + ID + ' wdt:P1417 ?ans. SERVICE wikibase:label { bd:serviceParam wikibase:language \"nl,en\". } }'\n",
    "    result1 = getAnswer(query1)\n",
    "    isAnimal = False\n",
    "    if result1 != []:\n",
    "        # If dictionary code starts with animal\n",
    "        if result1[0][:6] == 'animal':\n",
    "            isAnimal = True\n",
    "\n",
    "    query2 = 'SELECT ?ansLabel WHERE { wd:' + ID + ' schema:description ?ans. SERVICE wikibase:label { bd:serviceParam wikibase:language \"nl,en\". } FILTER (langMatches(lang(?ans),\"nl\")) }'\n",
    "    result2 = getAnswer(query2)\n",
    "    if result2 != []:\n",
    "        # If dier is in description, it probably is an animal.\n",
    "        if 'dier' in result2[0]:\n",
    "            isAnimal = True\n",
    "    return isAnimal\n",
    "\n",
    "# Removes articles 'de', 'het' and 'een' from the input\n",
    "def removeArticles(line):\n",
    "    lineSplit = line.lower().split()\n",
    "    articles = ['de', 'het', 'een']\n",
    "    for article in articles:\n",
    "        while article in lineSplit:\n",
    "            lineSplit.remove(article)\n",
    "    newLine = ' '.join(lineSplit)\n",
    "\n",
    "    return newLine\n",
    "\n",
    "# Function to retreive the keywords, based on the question given\n",
    "def getKeywords(question):\n",
    "    sentence = nlp(question)\n",
    "    keywords = {\n",
    "        'subject': '',\n",
    "        'property': ''\n",
    "    }\n",
    "    \n",
    "    # First find the property by looking at the subject of the sentence\n",
    "    for chunk in sentence.noun_chunks:\n",
    "        if chunk.root.dep_ == 'nsubj':\n",
    "            keywords['property'] = removeArticles(chunk.text)\n",
    "            subject_root = chunk.root.text\n",
    "        \n",
    "    # Then find the right subject, by comparing the root of the property to the head chunk x\n",
    "    for chunk in sentence.noun_chunks:\n",
    "        if chunk.root.head.text == subject_root:\n",
    "            keywords['subject'] = removeArticles(chunk.text)\n",
    "\n",
    "    return keywords\n",
    "\n",
    "# Function for creating possible queries for the retreived keywords\n",
    "def createQueries(question):\n",
    "    keywords = getKeywords(question)\n",
    "    IDx = getIDs(keywords['subject'])\n",
    "    ID1s = []\n",
    "    for ID in IDx:\n",
    "        if animalID(ID):\n",
    "            ID1s.append(ID)\n",
    "    ID2s = getIDs(keywords['property'], p=True)\n",
    "    qs = []\n",
    "    for ID1 in ID1s:\n",
    "        for ID2 in ID2s:\n",
    "            query = 'SELECT ?ansLabel WHERE { wd:' + ID1 + ' wdt:' + ID2 + ' ?ans. SERVICE wikibase:label { bd:serviceParam wikibase:language \"nl,en\". } }'\n",
    "            qs.append(query)\n",
    "    return qs\n",
    "\n",
    "def answerQuestion(question):\n",
    "    queries = createQueries(question)\n",
    "    answers = []\n",
    "    for query in queries:\n",
    "        answer = getAnswer(query)\n",
    "        if answer != []:\n",
    "            answers.append(answer)\n",
    "\n",
    "    for ans in answers:\n",
    "        for ansLabel in ans:\n",
    "            print(' -', ansLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_punct(sent):\n",
    "    clean_sent = ''\n",
    "    for char in sent:\n",
    "        if char not in ['.', ',', '?', '!']:\n",
    "            clean_sent += char\n",
    "    return clean_sent\n",
    "\n",
    "def find_pos(parse_sent, qword):\n",
    "    for word in parse_sent:\n",
    "        if word.text == qword:\n",
    "            funct = word.pos_\n",
    "\n",
    "    return funct\n",
    "\n",
    "def find_dep(parse_sent, qword):\n",
    "    for word in parse_sent:\n",
    "        if word.text == qword:\n",
    "            funct = word.dep_\n",
    "\n",
    "    return funct\n",
    "\n",
    "def find_root(sent, head):\n",
    "    parse = nlp(sent)\n",
    "    root = []\n",
    "    for word in parse:\n",
    "        if word.head.text == head:\n",
    "            root.append(word.text)\n",
    "    return root\n",
    "\n",
    "def find_head(sent, root):\n",
    "    parse = nlp(sent)\n",
    "    head = []\n",
    "    for word in parse:\n",
    "        if word.text == root:\n",
    "            head.append(word.head.text)\n",
    "    return head\n",
    "\n",
    "def analyse(s):\n",
    "    anal_d = {}\n",
    "    for word in s:\n",
    "        anal_d[word.text] = word.dep_\n",
    "    return anal_d\n",
    "\n",
    "def findSynonym(word):\n",
    "    synonym = word\n",
    "    for possibleword in ['hoogte', 'lengte', 'grootte', 'lang']:\n",
    "        if word == possibleword:\n",
    "            synonym = 'hoogte'\n",
    "        elif word == possibleword[:len(word)]:\n",
    "            synonym = 'hoogte'\n",
    "\n",
    "    return synonym\n",
    "\n",
    "q1 = 'welke kleur heeft een ijsbeer?'\n",
    "q2 = 'welke YSO-identificatiecode heeft de olifant?'\n",
    "q3 = 'hoe groot is een olifant?'\n",
    "def find_QP(sent):\n",
    "    sent_cl = rm_punct(sent)\n",
    "    query_dict = {}\n",
    "    parse = nlp(sent)\n",
    "\n",
    "    # questions starting with 'welke'\n",
    "    if parse[0].lemma_.lower() == 'welk':\n",
    "        anal_d = analyse(parse)\n",
    "        for word in sent_cl.split():\n",
    "            if word == find_head(sent_cl, word)[0]:\n",
    "                sent_ROOT = word\n",
    "        keys = find_root(sent_cl, sent_ROOT)\n",
    "        keys.remove(sent_ROOT)\n",
    "        for word in keys:\n",
    "            for root in find_root(sent_cl, word):\n",
    "                if root == parse[0].text: # parse[0] => .lemma.lower() == 'welk'\n",
    "                    query_dict['P'] = findSynonym(word)\n",
    "                else:\n",
    "                    query_dict['Q'] = findSynonym(word)\n",
    "    elif parse[0].lemma_.lower() == 'hoe':\n",
    "        anal_d = analyse(parse)\n",
    "        for word in sent_cl.split():\n",
    "            if word == find_head(sent_cl, word)[0]:\n",
    "                sent_ROOT = word\n",
    "                query_dict['P'] = findSynonym(sent_ROOT)\n",
    "            elif find_dep(parse, word) == 'nsubj':\n",
    "                query_dict['Q'] = findSynonym(word)\n",
    "    else: # wat vragen\n",
    "        d = getKeywords(sent)\n",
    "        query_dict['Q'] = d['subject']\n",
    "        query_dict['P'] = d['property']\n",
    "    \n",
    "    return query_dict\n",
    "\n",
    "\n",
    "def createQueries2(qIDs, pIDs):\n",
    "    ID1s = []\n",
    "    for ID in qIDs:\n",
    "        if animalID(ID):\n",
    "            ID1s.append(ID)\n",
    "    qs = []\n",
    "    for ID1 in ID1s:\n",
    "        for ID2 in pIDs:\n",
    "            query = 'SELECT ?ansLabel WHERE { wd:' + ID1 + ' wdt:' + ID2 + ' ?ans. SERVICE wikibase:label { bd:serviceParam wikibase:language \"nl,en\". } }'\n",
    "            qs.append(query)\n",
    "    return qs\n",
    "\n",
    "\n",
    "def answerQuestion2(question):\n",
    "    keys = find_QP(question)\n",
    "    q_ids = getIDs(keys['Q'])\n",
    "    p_ids = getIDs(keys['P'], p=True)\n",
    "    queries = createQueries2(q_ids, p_ids)\n",
    "    answers = []\n",
    "    for query in queries:\n",
    "        answer = getAnswer(query)\n",
    "        if answer != []:\n",
    "            answers.append(answer)\n",
    "\n",
    "    if len(answers) == 0:\n",
    "        print(' - Excuses. Ik heb op deze vraag geen antwoord kunnen vinden.')\n",
    "    else: \n",
    "        for ans in answers:\n",
    "            for ansLabel in ans:\n",
    "                print(' -', ansLabel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "Bij het implementeren van twee andere soorten vragen heb ik voor de vragen beginnend met 'Hoe ...' en 'Welke ...' gekozen. De complexere vragen zijn nog niet waterdicht beantwoord, maar de simpelere vragen beginnend met 'hoe', 'welke' of 'wat' (vorige opdracht) werken. Hier onder staan een aantal voorbeeld vragen die werken met het huidige vraag-antwoord systeem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = 'Hoe groot is een olifant?'\n",
    "q2 = 'Welke kleur heeft een ijsbeer?'\n",
    "q3 = 'Welke commonscategorie past bij de olifant?'\n",
    "q4 = 'Hoe lang is een giraffe?'\n",
    "q5 = 'Welke IUCN-status heeft de leeuw?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoe groot is een olifant?\n",
      " - 4\n",
      "\n",
      "Welke kleur heeft een ijsbeer?\n",
      " - wit\n",
      "\n",
      "Welke commonscategorie past bij de olifant?\n",
      " - Elephants\n",
      " - Elephants in heraldry\n",
      "\n",
      "Hoe lang is een giraffe?\n",
      " - 5.5\n",
      "\n",
      "Welke IUCN-status heeft de leeuw?\n",
      " - kwetsbare soort\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [q1, q2, q3, q4, q5]\n",
    "for q in questions:\n",
    "    print(q)\n",
    "    answerQuestion2(q)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Stel een vraag\n",
      " Wat is de bijtkracht van een leeuw?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = input('Stel een vraag\\n')\n",
    "answerQuestion2(question)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
